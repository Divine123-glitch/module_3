{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "b490c51f",
   "metadata": {},
   "source": [
    "\n",
    "# Home Loan EDA Notebook\n",
    "\n",
    "This notebook performs a complete Exploratory Data Analysis (EDA) on the Home Loan **train** and **test** datasets.\n",
    "It follows the project phases you provided:\n",
    "- Phase 1: Data collection & preparation\n",
    "- Phase 2: Exploratory Data Analysis (EDA)\n",
    "- Phase 3: Reporting & insights\n",
    "\n",
    "**How to use:** Run all cells from top to bottom. The notebook will save cleaned CSVs, figures, and a PDF-ready set of images to `/mnt/data/home_loan_eda_output`.\n",
    "\n",
    "**Notes:** The notebook pulls the datasets from the raw GitHub URLs. If your environment blocks internet access, download the CSVs locally and update the file paths in the \"Load data\" cell.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "83cdda60",
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'matplotlib'",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mModuleNotFoundError\u001b[39m                       Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[1]\u001b[39m\u001b[32m, line 6\u001b[39m\n\u001b[32m      4\u001b[39m \u001b[38;5;28;01mimport\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mpandas\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mas\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mpd\u001b[39;00m\n\u001b[32m      5\u001b[39m \u001b[38;5;28;01mimport\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mnumpy\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mas\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mnp\u001b[39;00m\n\u001b[32m----> \u001b[39m\u001b[32m6\u001b[39m \u001b[38;5;28;01mimport\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mmatplotlib\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mpyplot\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mas\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mplt\u001b[39;00m\n\u001b[32m      8\u001b[39m \u001b[38;5;66;03m# Configure output directories\u001b[39;00m\n\u001b[32m      9\u001b[39m OUT_DIR = Path(\u001b[33m\"\u001b[39m\u001b[33m/mnt/data/home_loan_eda_output\u001b[39m\u001b[33m\"\u001b[39m)\n",
      "\u001b[31mModuleNotFoundError\u001b[39m: No module named 'matplotlib'"
     ]
    }
   ],
   "source": [
    "\n",
    "# Imports and configuration\n",
    "import os\n",
    "from pathlib import Path\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Configure output directories\n",
    "OUT_DIR = Path(\"/mnt/data/home_loan_eda_output\")\n",
    "FIG_DIR = OUT_DIR / \"figures\"\n",
    "OUT_DIR.mkdir(parents=True, exist_ok=True)\n",
    "FIG_DIR.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "# Display settings\n",
    "pd.set_option('display.max_columns', 200)\n",
    "pd.set_option('display.width', 200)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f6c01863",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Data URLs (change to local paths if internet is unavailable)\n",
    "TRAIN_URL = \"https://raw.githubusercontent.com/ek-chris/Practice_datasets/refs/heads/main/home_loan_train.csv\"\n",
    "TEST_URL  = \"https://raw.githubusercontent.com/ek-chris/Practice_datasets/refs/heads/main/home_loan_test.csv\"\n",
    "\n",
    "def load_csv(url):\n",
    "    print(\"Loading:\", url)\n",
    "    df = pd.read_csv(url)\n",
    "    print(\"Shape:\", df.shape)\n",
    "    return df\n",
    "\n",
    "train = load_csv(TRAIN_URL)\n",
    "test = load_csv(TEST_URL)\n",
    "\n",
    "# Quick peek\n",
    "display(train.head())\n",
    "display(test.head())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "76f0a951",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Phase 1: Inspect datasets for missing values, duplicates, dtypes\n",
    "def inspect(df, name=\"data\"):\n",
    "    print(f\"--- {name} ---\")\n",
    "    print(\"Shape:\", df.shape)\n",
    "    print(\"Duplicates:\", df.duplicated().sum())\n",
    "    print(\"Missing counts:\")\n",
    "    print(df.isna().sum())\n",
    "    print(\"\\nData types:\")\n",
    "    print(df.dtypes)\n",
    "    print(\"\\nSummary stats (numerical):\")\n",
    "    display(df.describe(include=[np.number]).T)\n",
    "    print(\"\\nSummary stats (categorical):\")\n",
    "    display(df.describe(include=['object']).T)\n",
    "\n",
    "inspect(train, \"train\")\n",
    "inspect(test, \"test\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "65fc4a34",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Task 1.3: Cleaning function\n",
    "def clean_data(df):\n",
    "    df = df.copy()\n",
    "    # Standardize columns\n",
    "    df.columns = [c.strip() for c in df.columns]\n",
    "    # Replace common missing markers with NaN\n",
    "    df.replace(['', ' ', 'NA', 'N/A', 'na', 'nan', 'None'], np.nan, inplace=True)\n",
    "    # Trim object columns\n",
    "    for col in df.select_dtypes(['object']).columns:\n",
    "        df[col] = df[col].str.strip()\n",
    "    # Handle dependents: '3+' -> 3\n",
    "    if 'dependents' in df.columns:\n",
    "        df['dependents'] = df['dependents'].replace('3+', '3')\n",
    "        df['dependents'] = pd.to_numeric(df['dependents'], errors='coerce')\n",
    "    # Numeric conversions (common names)\n",
    "    mapping_nums = {\n",
    "        'applicantincome':'applicant_income','applicant_income':'applicant_income',\n",
    "        'coapplicantincome':'coapplicant_income','coapplicant_income':'coapplicant_income',\n",
    "        'loanamount':'loan_amount','loan_amount':'loan_amount',\n",
    "        'loan_amount_term':'loan_amount_term','loan_amount_term_months':'loan_amount_term'\n",
    "    }\n",
    "    for col in list(df.columns):\n",
    "        if col.lower() in mapping_nums:\n",
    "            try:\n",
    "                df[col] = pd.to_numeric(df[col], errors='coerce')\n",
    "            except:\n",
    "                pass\n",
    "    # Credit history numeric\n",
    "    if 'credit_history' in df.columns:\n",
    "        df['credit_history'] = pd.to_numeric(df['credit_history'], errors='coerce')\n",
    "    # Fill numeric missing with median (except target 'loan_status')\n",
    "    num_cols = df.select_dtypes(include=[np.number]).columns.tolist()\n",
    "    for col in num_cols:\n",
    "        if df[col].isna().sum() > 0:\n",
    "            df[col].fillna(df[col].median(), inplace=True)\n",
    "    # Fill categorical missing with 'Unknown' (do not touch loan_status if present and desired)\n",
    "    cat_cols = df.select_dtypes(include=['object']).columns.tolist()\n",
    "    for col in cat_cols:\n",
    "        if df[col].isna().sum() > 0:\n",
    "            df[col].fillna('Unknown', inplace=True)\n",
    "    return df\n",
    "\n",
    "train_clean = clean_data(train)\n",
    "test_clean  = clean_data(test)\n",
    "\n",
    "# Save cleaned copies\n",
    "train_clean.to_csv(OUT_DIR / \"train_cleaned.csv\", index=False)\n",
    "test_clean.to_csv(OUT_DIR / \"test_cleaned.csv\", index=False)\n",
    "\n",
    "print(\"Saved cleaned CSVs to\", OUT_DIR)\n",
    "display(train_clean.head())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e570a368",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Phase 2: Descriptive statistics and visualizations (matplotlib only)\n",
    "\n",
    "def save_fig(fig, name):\n",
    "    path = FIG_DIR / f\"{name}.png\"\n",
    "    fig.savefig(path, bbox_inches='tight', dpi=150)\n",
    "    plt.close(fig)\n",
    "    print(\"Saved\", path)\n",
    "    return path\n",
    "\n",
    "# 2.1 Descriptive stats\n",
    "print(\"Train numerical description:\")\n",
    "display(train_clean.describe().T)\n",
    "print(\"\\nTrain categorical description:\")\n",
    "display(train_clean.describe(include=['object']).T)\n",
    "\n",
    "# 2.2 Histograms and boxplots for key numeric features\n",
    "numeric_features = ['applicant_income','coapplicant_income','loan_amount','loan_amount_term','dependents','credit_history']\n",
    "# Filter only those present\n",
    "numeric_features = [f for f in numeric_features if f in train_clean.columns]\n",
    "\n",
    "for feat in numeric_features:\n",
    "    # Histogram\n",
    "    fig = plt.figure(figsize=(8,4))\n",
    "    plt.hist(train_clean[feat].dropna(), bins=30)\n",
    "    plt.title(f\"Train: {feat} distribution\")\n",
    "    plt.xlabel(feat); plt.ylabel(\"count\")\n",
    "    save_fig(fig, f\"train_hist_{feat}\")\n",
    "    # Boxplot by loan_status if available\n",
    "    if 'loan_status' in train_clean.columns:\n",
    "        fig = plt.figure(figsize=(8,4))\n",
    "        # create list of arrays for each status\n",
    "        groups = []\n",
    "        labels = []\n",
    "        for name, group in train_clean.groupby('loan_status'):\n",
    "            groups.append(group[feat].dropna())\n",
    "            labels.append(name)\n",
    "        plt.boxplot(groups, labels=labels)\n",
    "        plt.title(f\"Train: {feat} by loan_status\")\n",
    "        save_fig(fig, f\"train_box_{feat}_by_status\")\n",
    "\n",
    "# 2.3 Categorical feature counts (bar charts)\n",
    "categorical_features = ['education','self_employed','property_area','married']\n",
    "categorical_features = [f for f in categorical_features if f in train_clean.columns]\n",
    "for cat in categorical_features:\n",
    "    fig = plt.figure(figsize=(6,4))\n",
    "    counts = train_clean[cat].value_counts()\n",
    "    plt.bar(counts.index.astype(str), counts.values)\n",
    "    plt.title(f\"Train: {cat} value counts\")\n",
    "    plt.xticks(rotation=45, ha='right')\n",
    "    save_fig(fig, f\"train_bar_{cat}\")\n",
    "\n",
    "# 2.4 Scatterplots for relationships (applicant_income vs loan_amount)\n",
    "if 'applicant_income' in train_clean.columns and 'loan_amount' in train_clean.columns:\n",
    "    fig = plt.figure(figsize=(8,6))\n",
    "    plt.scatter(train_clean['applicant_income'], train_clean['loan_amount'], alpha=0.6)\n",
    "    plt.xlabel('applicant_income'); plt.ylabel('loan_amount')\n",
    "    plt.title('Applicant income vs Loan amount (train)')\n",
    "    save_fig(fig, 'train_scatter_income_loan')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b8c023f8",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# 2.4 Correlation matrix (numeric only) and cross-tabulations\n",
    "num = train_clean.select_dtypes(include=[np.number])\n",
    "corr = num.corr()\n",
    "\n",
    "# Save correlation heatmap using matplotlib\n",
    "fig = plt.figure(figsize=(8,6))\n",
    "plt.imshow(corr, interpolation='nearest')\n",
    "plt.colorbar()\n",
    "plt.xticks(range(len(corr.columns)), corr.columns, rotation=90)\n",
    "plt.yticks(range(len(corr.columns)), corr.columns)\n",
    "plt.title(\"Train: Correlation matrix (numeric)\")\n",
    "save_fig(fig, \"train_corr_matrix\")\n",
    "\n",
    "# Cross-tab: credit_history vs loan_status (percentage by row)\n",
    "if 'credit_history' in train_clean.columns and 'loan_status' in train_clean.columns:\n",
    "    ct = pd.crosstab(train_clean['credit_history'], train_clean['loan_status'], normalize='index') * 100\n",
    "    display(ct.round(2))\n",
    "    ct.to_csv(OUT_DIR / \"crosstab_credit_history_vs_status_pct.csv\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b403f4cf",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# 2.5 Identify outliers: Using IQR method for numeric features\n",
    "outlier_report = {}\n",
    "for col in numeric_features:\n",
    "    Q1 = train_clean[col].quantile(0.25)\n",
    "    Q3 = train_clean[col].quantile(0.75)\n",
    "    IQR = Q3 - Q1\n",
    "    low = Q1 - 1.5 * IQR\n",
    "    high = Q3 + 1.5 * IQR\n",
    "    outliers = train_clean[(train_clean[col] < low) | (train_clean[col] > high)]\n",
    "    outlier_report[col] = {\n",
    "        'low_threshold': low, 'high_threshold': high, 'num_outliers': len(outliers)\n",
    "    }\n",
    "\n",
    "import json\n",
    "print(\"Outlier summary:\")\n",
    "print(json.dumps(outlier_report, indent=2))\n",
    "\n",
    "# Save a small sample of outliers for review\n",
    "outlier_samples = pd.concat([train_clean[train_clean[col] > outlier_report[col]['high_threshold']].head(5) for col in numeric_features if outlier_report[col]['num_outliers']>0], ignore_index=True)\n",
    "outlier_samples.to_csv(OUT_DIR / \"outlier_samples.csv\", index=False)\n",
    "display(outlier_samples.head())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6b3fcaff",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Phase 3: Reporting & Insights (automated summary)\n",
    "summary = []\n",
    "\n",
    "# Basic approval rates\n",
    "if 'loan_status' in train_clean.columns:\n",
    "    approval_counts = train_clean['loan_status'].value_counts(normalize=True) * 100\n",
    "    summary.append(\"Loan approval distribution (train):\\n\" + approval_counts.round(2).to_string())\n",
    "\n",
    "# Credit history effect\n",
    "if 'credit_history' in train_clean.columns and 'loan_status' in train_clean.columns:\n",
    "    ct = pd.crosstab(train_clean['credit_history'], train_clean['loan_status'], normalize='index') * 100\n",
    "    summary.append(\"\\nCredit history vs Loan status (%)\\n\" + ct.round(2).to_string())\n",
    "\n",
    "# Education effect\n",
    "if 'education' in train_clean.columns and 'loan_status' in train_clean.columns:\n",
    "    ct2 = pd.crosstab(train_clean['education'], train_clean['loan_status'], normalize='index') * 100\n",
    "    summary.append(\"\\nEducation vs Loan status (%)\\n\" + ct2.round(2).to_string())\n",
    "\n",
    "# Output summary to text file\n",
    "summary_text = \"\\n\\n\".join(summary)\n",
    "with open(OUT_DIR / \"eda_summary.txt\", \"w\") as f:\n",
    "    f.write(summary_text)\n",
    "\n",
    "print(\"Summary written to\", OUT_DIR / \"eda_summary.txt\")\n",
    "print(\"\\n--- Summary preview ---\\n\")\n",
    "print(summary_text)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ff727ced",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# List created files\n",
    "for p in sorted(OUT_DIR.rglob(\"*\")):\n",
    "    print(p.relative_to(\"/mnt/data\"))\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "benv (3.14.0)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.14.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
